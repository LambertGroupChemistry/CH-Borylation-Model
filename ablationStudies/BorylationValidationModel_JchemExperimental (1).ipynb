{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for data manipulation and analysis\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required sklearn functions\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.inspection import permutation_importance\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import sklearn classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library to oversample \n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import RDKit and Mordred libraries\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from mordred import Calculator, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets Pandas Display to Monitor Code\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Mordred Calculator\n",
    "calc = Calculator(descriptors, ignore_3D=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Functions used in the study\n",
    "\n",
    "#Remove those numbers from analysis data\n",
    "def filter_rows_by_values1(df, col, values):\n",
    "    return df[~df[col].isin(values)]\n",
    "\n",
    "#Remove those numbers from analysis data\n",
    "def filter_rows_by_values2(df, col, values):\n",
    "    return df[df[col].isin(values)]\n",
    "\n",
    "#Get Mordred calcs\n",
    "def get_Mordred(data_input):\n",
    "    # Assigns Reactants Mordred Info\n",
    "    reactants = data_input['Substrate']\n",
    "    \n",
    "    reactants_mol_list = []\n",
    "    for inChi_reactants in reactants:\n",
    "      reactants_mol = Chem.MolFromInchi(inChi_reactants)\n",
    "      reactants_mol_list.append(reactants_mol)\n",
    "\n",
    "    # Puts reactants into Pandas Type\n",
    "    reactant_data = []\n",
    "    reactant_data = calc.pandas(reactants_mol_list)\n",
    "       \n",
    "    #Joins Mordred parameters with experimental, atomic charges, and JChem for Excel parameters\n",
    "    add_reactants = pd.concat((data_input, reactant_data), axis=1)\n",
    "    \n",
    "    #Force any non-numeric entries as NaN and replace them with 0\n",
    "    int_data = add_reactants.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    output = int_data.fillna(0)#, inplace=True)\n",
    "\n",
    "    return output\n",
    "\n",
    "#Remove zero varience\n",
    "def remove_zero_varience(values):\n",
    "   sel = VarianceThreshold()\n",
    "   _ = sel.fit(values)\n",
    "   mask = sel.get_support()\n",
    "   values = values.loc[:,mask] \n",
    "   return values\n",
    "\n",
    "def remove_95correlated(correlated):\n",
    "    #Remove any features that are greater than 95% correlated\n",
    "    corr_matrix = correlated.corr()\n",
    "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(np.bool))\n",
    "\n",
    "    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n",
    "\n",
    "    correlated = correlated.drop(to_drop, axis = 1)\n",
    "    corr_matrix = correlated.corr()\n",
    "    return correlated\n",
    "\n",
    "def remove_nonimportant(X_values, y_values):\n",
    "    # Specifys Random Forest and the Number of Trees, SelectFromModel will\n",
    "    # select features which are most important\n",
    "    feature_names = [f\"feature {i}\" for i in range(X_values.shape[1])]\n",
    "    forest = RandomForestClassifier(random_state=42)\n",
    "    forest.fit(X_values, y_values)\n",
    "\n",
    "    start_time = time.time()\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    threshold = np.sort(importances)[-100]\n",
    "    \n",
    "    sel = SelectFromModel(RandomForestClassifier(n_estimators = 800, max_depth=30),threshold=threshold)\n",
    "    sel.fit(X_values, y_values)\n",
    "\n",
    "    # Select the final features set \n",
    "    sel.get_support()\n",
    "    selected_feat= X_values.columns[(sel.get_support())]\n",
    "\n",
    "    # Prints the names of the final selected features\n",
    "    print(selected_feat)\n",
    "    X_values = X_values[selected_feat]\n",
    "    \n",
    "    return X_values\n",
    "\n",
    "def dendrogram(X_values, y):\n",
    "    corr = spearmanr(X_values).correlation\n",
    "    # Ensure the correlation matrix is symmetric\n",
    "    corr = (corr + corr.T) / 2\n",
    "    np.fill_diagonal(corr, 1)\n",
    "    distance_matrix = 1 - np.abs(corr)\n",
    "    dist_linkage = hierarchy.ward(squareform(distance_matrix))\n",
    "  \n",
    "    trained_cluster_ids = hierarchy.fcluster(dist_linkage, y, criterion=\"distance\")\n",
    "    trained_cluster_id_to_feature_ids = defaultdict(list) \n",
    "    for idx, trained_cluster_id in enumerate(trained_cluster_ids):\n",
    "        trained_cluster_id_to_feature_ids[trained_cluster_id].append(idx)\n",
    "    \n",
    "    trained_selected_features = [v[0] for v in trained_cluster_id_to_feature_ids.values()]\n",
    "    final_selected_features = X_values.columns[trained_selected_features]\n",
    "    X_train = X_values[final_selected_features]\n",
    "    return X_train\n",
    "\n",
    "def classificationMetrics(results, y_test, pred):\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    prec = precision_score(y_test, pred, average=None, zero_division=0)\n",
    "    recall = recall_score(y_test, pred, average=None)\n",
    "    F1 = f1_score(y_test, pred, average=None)           \n",
    "    #Calculate confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_test, pred)\n",
    "    cf_matrix = np.reshape(cf_matrix,(1,4))\n",
    "    comb = np.concatenate((x, y, cf_matrix, acc, prec, recall, F1), axis=None)\n",
    "    comb = [comb]\n",
    "    results = results.append(pd.DataFrame(comb, columns=results.columns), ignore_index=True)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Training/Test data input File\n",
    "data = pd.read_csv('BorylationTrainingTest 9-12-24.csv')\n",
    "\n",
    "#group the compounds by numbers\n",
    "data['grouped'] = data.groupby('Substrate', sort=False).ngroup()\n",
    "\n",
    "# Seperate dataset as response variable and feature variables\n",
    "data = data.drop(['Substrate','Hirshfeld Heavy Atom Charge','CM5 Charge','Hirshfeld Carbon Charge','Hirshfeld Hydrogen Charge',\n",
    "              'ESP Heavy Atom Charge','ESP Carbon Charge','ESP Hydrogen Charge','NPA Carbon Charge','NPA Hydrogen Charge',\n",
    "              'MBS Heavy Atom Charge','MBS Carbon Charge','MBS Hydrogen Charge','Mulliken Heavy Charge','Mulliken Carbon Charge',\n",
    "              'Mulliken Hydrogen Charge','Product'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Results_df = pd.DataFrame(columns =  ['x', 'y',  \"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\",'acc', 'precision 0',\n",
    "                                   'precision 1','recall 0', 'recall 1', 'F1 0', 'F1 1'])\n",
    "\n",
    "maxacc_comb = pd.DataFrame()\n",
    "val_tot = pd.DataFrame()\n",
    "prod = pd.DataFrame()\n",
    "test_index_total = pd.DataFrame()\n",
    "\n",
    "model_columns = pd.DataFrame()\n",
    "for_range = range(1, 11)\n",
    "for x in for_range:\n",
    "    #Get numbers to represent compounds\n",
    "    arr = np.arange(0, 200,  dtype=int)\n",
    "\n",
    "    #Get 20% of numbers, without replacement\n",
    "    set_numbers = np.random.choice(arr, int(len(arr)*0.20), replace=False ) \n",
    "    \n",
    "    #Seperate training (80%) and test data (20%)\n",
    "    training_data = filter_rows_by_values1(data, \"grouped\", set_numbers)\n",
    "    test_data = filter_rows_by_values2(data, \"grouped\", set_numbers)\n",
    "  \n",
    "    #Remove features that dont change\n",
    "    training_data = remove_zero_varience(training_data)\n",
    "    \n",
    "    #Remove features that are more than 95% correlated\n",
    "    training_data = remove_95correlated(training_data)\n",
    "    \n",
    "    # Seperate dataset as response variable (Product Ratio) and feature variables\n",
    "    #Note: Product Ratio is described as \"0\" for non-borylating sites and \"1\" for borylating sites\n",
    "    training_X = training_data.drop('Product_Ratio', axis = 1)\n",
    "    training_X = training_X.drop('grouped', axis = 1)\n",
    "    training_y = training_data['Product_Ratio']\n",
    "    test_X = test_data.drop('Product_Ratio', axis = 1)\n",
    "    test_X = test_X.drop('grouped', axis = 1)\n",
    "    test_y = test_data['Product_Ratio']\n",
    " \n",
    "    #Remove features that are considered less important\n",
    "    feature_names = [f\"feature {i}\" for i in range(training_X.shape[1])]\n",
    "    forest = RandomForestClassifier(random_state=42)\n",
    "    forest.fit(training_X, training_y)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    threshold = np.sort(importances)[-23] \n",
    "    sel = SelectFromModel(RandomForestClassifier(n_estimators = 800, max_depth=30),threshold=threshold)\n",
    "    sel.fit(training_X, training_y)\n",
    "     \n",
    "    # Select the reduced features set \n",
    "    sel.get_support()\n",
    "    selected_feat= training_X.columns[(sel.get_support())]\n",
    "    \n",
    "    reduced1_X = training_X[selected_feat]\n",
    "    test_X = test_X[selected_feat]\n",
    "    \n",
    "    #Apply over-sampling to dataset\n",
    "    ros = RandomOverSampler(random_state=10)\n",
    "    X_resampled, y_resampled = ros.fit_resample(reduced1_X, training_y) \n",
    "    \n",
    "    for y in [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
    "              0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30, \n",
    "              0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35,\n",
    "              0.40, 0.40, 0.40, 0.40, 0.40, 0.40, 0.40, 0.40, 0.40, 0.40, \n",
    "              0.45, 0.45, 0.45, 0.45, 0.45, 0.45, 0.45, 0.45, 0.45, 0.45,\n",
    "              0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50,\n",
    "              0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.55]:\n",
    "             \n",
    "    \n",
    "        #Make final training and test set and save them as df's  \n",
    "        X_train = dendrogram(X_resampled, y)\n",
    "        test_X = test_X[X_train.columns]\n",
    "        training_columns_list = X_train.columns.tolist()\n",
    "        training_columns_list = (x, y, training_columns_list)\n",
    "        training_columns_list = (pd.DataFrame(training_columns_list).T)\n",
    "\n",
    "        #Random Forest Classifier\n",
    "        rfc = RandomForestClassifier(n_estimators=800,max_depth=9)\n",
    "        rfc.fit(X_train, y_resampled)\n",
    "        pred = rfc.predict(test_X)\n",
    "        Results_df = classificationMetrics(Results_df, test_y, pred)\n",
    "\n",
    "        #Evaluate model by going line by line\n",
    "        ynew = rfc.predict(test_X)\n",
    "        prediction_df = pd.DataFrame(ynew,  columns = [(x,y)])\n",
    "\n",
    "        val_pred_T = prediction_df.T\n",
    "        val_tot = val_tot.append(val_pred_T)\n",
    "\n",
    "        #Determine the mean accuracy of the different dendrogram settings\n",
    "        acc_mean = Results_df.groupby('y')['acc'].mean()\n",
    "        acc_std = Results_df.groupby('y')['acc'].std()\n",
    "        precision_0_mean = Results_df.groupby('y')['precision 0'].mean()\n",
    "        precision_0_std = Results_df.groupby('y')['precision 0'].std()\n",
    "        precision_1_mean = Results_df.groupby('y')['precision 1'].mean()\n",
    "        precision_1_std = Results_df.groupby('y')['precision 1'].std()\n",
    "        recall_0_mean = Results_df.groupby('y')['recall 0'].mean()\n",
    "        recall_0_std = Results_df.groupby('y')['recall 0'].std()\n",
    "        recall_1_mean = Results_df.groupby('y')['recall 1'].mean()\n",
    "        recall_1_std = Results_df.groupby('y')['recall 1'].std()\n",
    "        F1_0_mean = Results_df.groupby('y')['F1 0'].mean()\n",
    "        F1_0_std = Results_df.groupby('y')['F1 0'].std()\n",
    "        F1_1_mean = Results_df.groupby('y')['F1 1'].mean()\n",
    "        F1_1_std = Results_df.groupby('y')['F1 1'].std()\n",
    "        true_neg_mean = Results_df.groupby('y')['True Neg'].mean()\n",
    "        true_neg_std = Results_df.groupby('y')['True Neg'].std()\n",
    "        false_pos_mean = Results_df.groupby('y')['False Pos'].mean()\n",
    "        false_pos_std = Results_df.groupby('y')['False Pos'].std()        \n",
    "        false_neg_mean = Results_df.groupby('y')['False Neg'].mean()\n",
    "        false_neg_std = Results_df.groupby('y')['False Neg'].std()      \n",
    "        true_pos_mean = Results_df.groupby('y')['True Pos'].mean() \n",
    "        true_pos_std = Results_df.groupby('y')['True Pos'].std()   \n",
    "        \n",
    "\n",
    "        average_df = pd.concat([acc_mean , acc_std, \n",
    "                                   precision_0_mean, precision_0_std, \n",
    "                                   precision_1_mean, precision_1_std, \n",
    "                                   recall_0_mean, recall_0_std, \n",
    "                                   recall_1_mean, recall_1_std,\n",
    "                                   F1_0_mean, F1_0_std,\n",
    "                                   F1_1_mean, F1_1_std,\n",
    "                                   true_neg_mean, true_neg_std,\n",
    "                                   false_pos_mean, false_pos_std,\n",
    "                                   false_neg_mean, false_neg_std,\n",
    "                                   true_pos_mean, true_pos_std], axis=1)\n",
    "    \n",
    "        average_df.columns = ['acc_mean' , 'acc_std', 'precision_0_mean', 'precision_0_std', \n",
    "                                 'precision_1_mean', 'precision_1_std', 'recall_0_mean', 'recall_0_std', \n",
    "                                 'recall_1_mean','recall_1_std', 'F1_0_mean', 'F1_0_std', \n",
    "                                 'F1_1_mean', 'F1_1_std', 'true_neg_mean', 'true_neg_std',\n",
    "                                 'false_pos_mean', 'false_pos_std','false_neg_mean', 'false_neg_std',\n",
    "                                 'true_pos_mean', 'true_pos_std']                                 \n",
    "\n",
    "        maxacc = average_df[average_df.acc_mean == average_df.acc_mean.max()]\n",
    "        maxacc_copy  = maxacc.copy()\n",
    "        maxacc_copy['x_col'] = x\n",
    "        \n",
    "        model_columns = model_columns.append(training_columns_list)\n",
    "        #print(x,y)\n",
    "    test_index = pd.DataFrame(test_data.index.values)\n",
    "    test_index_total = pd.concat([test_index_total, test_index],axis = 1)\n",
    "    test_y = test_y.rename(x)\n",
    "    prod = prod.append(test_y)\n",
    "    maxacc_comb = maxacc_comb.append(maxacc_copy)  \n",
    "\n",
    "total_results = val_tot.T\n",
    " \n",
    "maxacc_comb.to_csv(\"JchemExp.csv\")\n",
    "model_columns = model_columns.rename(columns = {0:'x', 1:'y', 2: 'features'})\n",
    "model_columns = model_columns.drop_duplicates(subset = ['x','y'])\n",
    "model_columns.to_csv(\"JchemExp.csv\", mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>acc_std</th>\n",
       "      <th>precision_0_mean</th>\n",
       "      <th>precision_0_std</th>\n",
       "      <th>precision_1_mean</th>\n",
       "      <th>precision_1_std</th>\n",
       "      <th>recall_0_mean</th>\n",
       "      <th>recall_0_std</th>\n",
       "      <th>recall_1_mean</th>\n",
       "      <th>recall_1_std</th>\n",
       "      <th>F1_0_mean</th>\n",
       "      <th>F1_0_std</th>\n",
       "      <th>F1_1_mean</th>\n",
       "      <th>F1_1_std</th>\n",
       "      <th>true_neg_mean</th>\n",
       "      <th>true_neg_std</th>\n",
       "      <th>false_pos_mean</th>\n",
       "      <th>false_pos_std</th>\n",
       "      <th>false_neg_mean</th>\n",
       "      <th>false_neg_std</th>\n",
       "      <th>true_pos_mean</th>\n",
       "      <th>true_pos_std</th>\n",
       "      <th>x_col</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>0.724286</td>\n",
       "      <td>0.011973</td>\n",
       "      <td>0.873466</td>\n",
       "      <td>0.007765</td>\n",
       "      <td>0.350755</td>\n",
       "      <td>0.018579</td>\n",
       "      <td>0.771176</td>\n",
       "      <td>0.013711</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.819074</td>\n",
       "      <td>0.008758</td>\n",
       "      <td>0.420332</td>\n",
       "      <td>0.021873</td>\n",
       "      <td>131.100000</td>\n",
       "      <td>2.330951</td>\n",
       "      <td>38.900000</td>\n",
       "      <td>2.330951</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.35</th>\n",
       "      <td>0.720296</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.864422</td>\n",
       "      <td>0.005590</td>\n",
       "      <td>0.350164</td>\n",
       "      <td>0.020040</td>\n",
       "      <td>0.773366</td>\n",
       "      <td>0.012954</td>\n",
       "      <td>0.501250</td>\n",
       "      <td>0.048310</td>\n",
       "      <td>0.816271</td>\n",
       "      <td>0.005762</td>\n",
       "      <td>0.412109</td>\n",
       "      <td>0.029917</td>\n",
       "      <td>126.900000</td>\n",
       "      <td>6.734827</td>\n",
       "      <td>37.100000</td>\n",
       "      <td>1.071153</td>\n",
       "      <td>19.950000</td>\n",
       "      <td>1.932411</td>\n",
       "      <td>20.050000</td>\n",
       "      <td>1.932411</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.45</th>\n",
       "      <td>0.720296</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.007061</td>\n",
       "      <td>0.356039</td>\n",
       "      <td>0.019534</td>\n",
       "      <td>0.765994</td>\n",
       "      <td>0.014056</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.053726</td>\n",
       "      <td>0.814822</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.426102</td>\n",
       "      <td>0.031064</td>\n",
       "      <td>125.700000</td>\n",
       "      <td>6.921363</td>\n",
       "      <td>38.300000</td>\n",
       "      <td>1.080935</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>2.149051</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>2.149051</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.731053</td>\n",
       "      <td>0.019518</td>\n",
       "      <td>0.879064</td>\n",
       "      <td>0.014238</td>\n",
       "      <td>0.370288</td>\n",
       "      <td>0.028824</td>\n",
       "      <td>0.772705</td>\n",
       "      <td>0.020273</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>0.060506</td>\n",
       "      <td>0.822325</td>\n",
       "      <td>0.014856</td>\n",
       "      <td>0.444468</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>128.900000</td>\n",
       "      <td>8.044488</td>\n",
       "      <td>37.766667</td>\n",
       "      <td>2.028815</td>\n",
       "      <td>17.733333</td>\n",
       "      <td>2.420221</td>\n",
       "      <td>22.266667</td>\n",
       "      <td>2.420221</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.721843</td>\n",
       "      <td>0.023465</td>\n",
       "      <td>0.871656</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>0.364053</td>\n",
       "      <td>0.027353</td>\n",
       "      <td>0.765695</td>\n",
       "      <td>0.021588</td>\n",
       "      <td>0.543750</td>\n",
       "      <td>0.057107</td>\n",
       "      <td>0.815143</td>\n",
       "      <td>0.018076</td>\n",
       "      <td>0.435890</td>\n",
       "      <td>0.037214</td>\n",
       "      <td>124.600000</td>\n",
       "      <td>10.257705</td>\n",
       "      <td>37.900000</td>\n",
       "      <td>1.822931</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>2.284283</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>2.284283</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.733832</td>\n",
       "      <td>0.032827</td>\n",
       "      <td>0.866683</td>\n",
       "      <td>0.018447</td>\n",
       "      <td>0.369381</td>\n",
       "      <td>0.034583</td>\n",
       "      <td>0.790544</td>\n",
       "      <td>0.038534</td>\n",
       "      <td>0.499000</td>\n",
       "      <td>0.054856</td>\n",
       "      <td>0.826477</td>\n",
       "      <td>0.025275</td>\n",
       "      <td>0.422668</td>\n",
       "      <td>0.031196</td>\n",
       "      <td>131.360000</td>\n",
       "      <td>13.845739</td>\n",
       "      <td>34.440000</td>\n",
       "      <td>5.357276</td>\n",
       "      <td>20.040000</td>\n",
       "      <td>2.194241</td>\n",
       "      <td>19.960000</td>\n",
       "      <td>2.194241</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.742279</td>\n",
       "      <td>0.035643</td>\n",
       "      <td>0.868265</td>\n",
       "      <td>0.017219</td>\n",
       "      <td>0.374629</td>\n",
       "      <td>0.034420</td>\n",
       "      <td>0.802066</td>\n",
       "      <td>0.043968</td>\n",
       "      <td>0.488333</td>\n",
       "      <td>0.055895</td>\n",
       "      <td>0.833365</td>\n",
       "      <td>0.027895</td>\n",
       "      <td>0.421694</td>\n",
       "      <td>0.028875</td>\n",
       "      <td>136.116667</td>\n",
       "      <td>16.586794</td>\n",
       "      <td>33.050000</td>\n",
       "      <td>5.875618</td>\n",
       "      <td>20.466667</td>\n",
       "      <td>2.235815</td>\n",
       "      <td>19.533333</td>\n",
       "      <td>2.235815</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.751657</td>\n",
       "      <td>0.040314</td>\n",
       "      <td>0.868838</td>\n",
       "      <td>0.016012</td>\n",
       "      <td>0.385092</td>\n",
       "      <td>0.041390</td>\n",
       "      <td>0.815827</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.473571</td>\n",
       "      <td>0.063401</td>\n",
       "      <td>0.840761</td>\n",
       "      <td>0.031619</td>\n",
       "      <td>0.420593</td>\n",
       "      <td>0.027257</td>\n",
       "      <td>140.671429</td>\n",
       "      <td>19.016942</td>\n",
       "      <td>31.042857</td>\n",
       "      <td>7.359182</td>\n",
       "      <td>21.057143</td>\n",
       "      <td>2.536034</td>\n",
       "      <td>18.942857</td>\n",
       "      <td>2.536034</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.749348</td>\n",
       "      <td>0.038283</td>\n",
       "      <td>0.870114</td>\n",
       "      <td>0.015352</td>\n",
       "      <td>0.380817</td>\n",
       "      <td>0.040493</td>\n",
       "      <td>0.811377</td>\n",
       "      <td>0.051052</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.061675</td>\n",
       "      <td>0.838999</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.420588</td>\n",
       "      <td>0.025612</td>\n",
       "      <td>140.350000</td>\n",
       "      <td>17.804209</td>\n",
       "      <td>32.025000</td>\n",
       "      <td>7.384512</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>2.466997</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>2.466997</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.746576</td>\n",
       "      <td>0.036956</td>\n",
       "      <td>0.866005</td>\n",
       "      <td>0.018608</td>\n",
       "      <td>0.370680</td>\n",
       "      <td>0.047914</td>\n",
       "      <td>0.812809</td>\n",
       "      <td>0.048304</td>\n",
       "      <td>0.460278</td>\n",
       "      <td>0.080805</td>\n",
       "      <td>0.837851</td>\n",
       "      <td>0.028475</td>\n",
       "      <td>0.406731</td>\n",
       "      <td>0.046287</td>\n",
       "      <td>140.233333</td>\n",
       "      <td>16.780172</td>\n",
       "      <td>31.766667</td>\n",
       "      <td>7.002488</td>\n",
       "      <td>21.588889</td>\n",
       "      <td>3.232192</td>\n",
       "      <td>18.411111</td>\n",
       "      <td>3.232192</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.743803</td>\n",
       "      <td>0.036085</td>\n",
       "      <td>0.864232</td>\n",
       "      <td>0.018532</td>\n",
       "      <td>0.370245</td>\n",
       "      <td>0.045648</td>\n",
       "      <td>0.810005</td>\n",
       "      <td>0.046604</td>\n",
       "      <td>0.461250</td>\n",
       "      <td>0.077065</td>\n",
       "      <td>0.835593</td>\n",
       "      <td>0.027877</td>\n",
       "      <td>0.407225</td>\n",
       "      <td>0.044264</td>\n",
       "      <td>138.060000</td>\n",
       "      <td>17.208654</td>\n",
       "      <td>31.840000</td>\n",
       "      <td>6.648035</td>\n",
       "      <td>21.550000</td>\n",
       "      <td>3.082617</td>\n",
       "      <td>18.450000</td>\n",
       "      <td>3.082617</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acc_mean   acc_std  precision_0_mean  precision_0_std  precision_1_mean  \\\n",
       "y                                                                               \n",
       "0.30  0.724286  0.011973          0.873466         0.007765          0.350755   \n",
       "0.35  0.720296  0.005548          0.864422         0.005590          0.350164   \n",
       "0.45  0.720296  0.004576          0.870588         0.007061          0.356039   \n",
       "0.50  0.731053  0.019518          0.879064         0.014238          0.370288   \n",
       "0.50  0.721843  0.023465          0.871656         0.017929          0.364053   \n",
       "0.25  0.733832  0.032827          0.866683         0.018447          0.369381   \n",
       "0.25  0.742279  0.035643          0.868265         0.017219          0.374629   \n",
       "0.25  0.751657  0.040314          0.868838         0.016012          0.385092   \n",
       "0.25  0.749348  0.038283          0.870114         0.015352          0.380817   \n",
       "0.25  0.746576  0.036956          0.866005         0.018608          0.370680   \n",
       "0.25  0.743803  0.036085          0.864232         0.018532          0.370245   \n",
       "\n",
       "      precision_1_std  recall_0_mean  recall_0_std  recall_1_mean  \\\n",
       "y                                                                   \n",
       "0.30         0.018579       0.771176      0.013711       0.525000   \n",
       "0.35         0.020040       0.773366      0.012954       0.501250   \n",
       "0.45         0.019534       0.765994      0.014056       0.531250   \n",
       "0.50         0.028824       0.772705      0.020273       0.556667   \n",
       "0.50         0.027353       0.765695      0.021588       0.543750   \n",
       "0.25         0.034583       0.790544      0.038534       0.499000   \n",
       "0.25         0.034420       0.802066      0.043968       0.488333   \n",
       "0.25         0.041390       0.815827      0.053000       0.473571   \n",
       "0.25         0.040493       0.811377      0.051052       0.480000   \n",
       "0.25         0.047914       0.812809      0.048304       0.460278   \n",
       "0.25         0.045648       0.810005      0.046604       0.461250   \n",
       "\n",
       "      recall_1_std  F1_0_mean  F1_0_std  F1_1_mean  F1_1_std  true_neg_mean  \\\n",
       "y                                                                             \n",
       "0.30      0.033333   0.819074  0.008758   0.420332  0.021873     131.100000   \n",
       "0.35      0.048310   0.816271  0.005762   0.412109  0.029917     126.900000   \n",
       "0.45      0.053726   0.814822  0.005587   0.426102  0.031064     125.700000   \n",
       "0.50      0.060506   0.822325  0.014856   0.444468  0.039254     128.900000   \n",
       "0.50      0.057107   0.815143  0.018076   0.435890  0.037214     124.600000   \n",
       "0.25      0.054856   0.826477  0.025275   0.422668  0.031196     131.360000   \n",
       "0.25      0.055895   0.833365  0.027895   0.421694  0.028875     136.116667   \n",
       "0.25      0.063401   0.840761  0.031619   0.420593  0.027257     140.671429   \n",
       "0.25      0.061675   0.838999  0.030000   0.420588  0.025612     140.350000   \n",
       "0.25      0.080805   0.837851  0.028475   0.406731  0.046287     140.233333   \n",
       "0.25      0.077065   0.835593  0.027877   0.407225  0.044264     138.060000   \n",
       "\n",
       "      true_neg_std  false_pos_mean  false_pos_std  false_neg_mean  \\\n",
       "y                                                                   \n",
       "0.30      2.330951       38.900000       2.330951       19.000000   \n",
       "0.35      6.734827       37.100000       1.071153       19.950000   \n",
       "0.45      6.921363       38.300000       1.080935       18.750000   \n",
       "0.50      8.044488       37.766667       2.028815       17.733333   \n",
       "0.50     10.257705       37.900000       1.822931       18.250000   \n",
       "0.25     13.845739       34.440000       5.357276       20.040000   \n",
       "0.25     16.586794       33.050000       5.875618       20.466667   \n",
       "0.25     19.016942       31.042857       7.359182       21.057143   \n",
       "0.25     17.804209       32.025000       7.384512       20.800000   \n",
       "0.25     16.780172       31.766667       7.002488       21.588889   \n",
       "0.25     17.208654       31.840000       6.648035       21.550000   \n",
       "\n",
       "      false_neg_std  true_pos_mean  true_pos_std  x_col  \n",
       "y                                                        \n",
       "0.30       1.333333      21.000000      1.333333      1  \n",
       "0.35       1.932411      20.050000      1.932411      2  \n",
       "0.45       2.149051      21.250000      2.149051      2  \n",
       "0.50       2.420221      22.266667      2.420221      3  \n",
       "0.50       2.284283      21.750000      2.284283      4  \n",
       "0.25       2.194241      19.960000      2.194241      5  \n",
       "0.25       2.235815      19.533333      2.235815      6  \n",
       "0.25       2.536034      18.942857      2.536034      7  \n",
       "0.25       2.466997      19.200000      2.466997      8  \n",
       "0.25       3.232192      18.411111      3.232192      9  \n",
       "0.25       3.082617      18.450000      3.082617     10  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxacc_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [00:12<00:00,  6.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Ratio</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Product_Ratio  1  2  3  4  5  6  7  8  9  10\n",
       "0               0  0  0  0  0  0  0  0  0  0   0\n",
       "1               0  0  0  0  0  0  0  0  0  0   0\n",
       "2               0  0  0  0  0  0  0  0  0  0   0\n",
       "3               0  0  0  0  0  0  0  0  0  0   0\n",
       "4               0  0  0  0  0  0  0  0  0  0   0\n",
       "..            ... .. .. .. .. .. .. .. .. ..  ..\n",
       "76              1  1  1  0  1  0  0  1  0  0   0\n",
       "77              0  1  0  0  0  0  0  0  0  0   0\n",
       "78              0  1  1  1  1  1  1  1  1  1   1\n",
       "79              0  1  0  0  0  0  0  0  0  0   0\n",
       "80              0  1  0  1  1  0  1  1  1  1   1\n",
       "\n",
       "[81 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = ['Solvent', 'Temp', 'Aliphatic Atom Count', 'Aromatic Atom Count', 'Steric Effect Index', 'Atomic_Polarizability', 'Balaban Index', 'Distance Degree', 'Dreiding Energy', \n",
    "                     'Eccentricity', 'Hydrogen Acceptor Count', 'Hydrogen Donor Count', 'MaxZ', 'Sigma Electronegativity']\n",
    "\n",
    "\n",
    "#Loads validation dataset for borlation using the final reduced features \n",
    "unknownSubstrates=pd.read_csv('validation8-26-24.csv')\n",
    "\n",
    "# Convert validation substrates Inchi's to Mordred and combine into Dataframe with atomic charges and JChem paramters\n",
    "New_Substrate = unknownSubstrates['Substrate']\n",
    "New_Substrate_mol_list = []\n",
    "for inChi_New_Substrate in New_Substrate:\n",
    "  New_Substrate_mol = Chem.MolFromInchi(inChi_New_Substrate)\n",
    "  New_Substrate_mol_list.append(New_Substrate_mol)\n",
    "\n",
    "New_Substrate_data = []\n",
    "New_Substrate_data = calc.pandas(New_Substrate_mol_list)\n",
    "New_Substrate_data = New_Substrate_data.apply(pd.to_numeric, errors='coerce')\n",
    "New_Substrate_data.fillna(0, inplace=True)                                                                  \n",
    "XnewSec = pd.concat((unknownSubstrates, New_Substrate_data), axis=1)\n",
    "Xnew = XnewSec[selected_features]\n",
    "\n",
    "val_tot = pd.DataFrame()\n",
    "\n",
    "for_range = range(1, 11)\n",
    "for x in for_range:\n",
    "    #Get numbers to represent compounds\n",
    "    arr = np.arange(0, 200,  dtype=int)\n",
    "\n",
    "    #Get 20% of numbers, without replacement\n",
    "    set_numbers = np.random.choice(arr, int(len(arr)*0.20), replace=False ) \n",
    "    \n",
    "    #Seperate training (80%) and test data (20%)\n",
    "    training_data = filter_rows_by_values1(data, \"grouped\", set_numbers)\n",
    "    test_data = filter_rows_by_values2(data, \"grouped\", set_numbers)\n",
    "   \n",
    "    # Seperate dataset as response variable (Product Ratio) and feature variables\n",
    "    #Note: Product Ratio is described as \"0\" for non-borylating sites and \"1\" for borylating sites\n",
    "    training_X = training_data.drop('Product_Ratio' , axis = 1)\n",
    "    training_y = training_data['Product_Ratio']\n",
    "    test_X = test_data.drop('Product_Ratio' , axis = 1)\n",
    "    test_y = test_data['Product_Ratio']\n",
    "   \n",
    "    #Apply over-sampling to training set\n",
    "    ros = RandomOverSampler(random_state=10)\n",
    "    X_resampled, y_resampled = ros.fit_resample(training_X, training_y)    \n",
    "    X_train = X_resampled[selected_features]\n",
    "\n",
    "    #Random Forest Classifier\n",
    "    rfc = RandomForestClassifier(n_estimators=800,max_depth=9)\n",
    "    rfc.fit(X_train, y_resampled)\n",
    "    \n",
    "    #Evaluate the model on validation set\n",
    "    ynew = rfc.predict(Xnew)\n",
    "    validation_prediction_df = pd.DataFrame(ynew, columns = [(x)])\n",
    "    validation_prediction_df.merge(validation_prediction_df, on=x)\n",
    "    val_pred_T = validation_prediction_df.T\n",
    "    val_tot = val_tot.append(val_pred_T)        \n",
    "\n",
    "#Print the validation evaluations for model\n",
    "unknownSubstrates_prod = unknownSubstrates['Product_Ratio']\n",
    "total_val_results_transposed = val_tot.T\n",
    "Val_results = pd.concat((unknownSubstrates_prod, total_val_results_transposed), axis=1)\n",
    "\n",
    "#Write the results onto a CSV file \n",
    "\n",
    "Val_results.to_csv(\"JchemExp.csv\", mode=\"a\")\n",
    "\n",
    "Val_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
